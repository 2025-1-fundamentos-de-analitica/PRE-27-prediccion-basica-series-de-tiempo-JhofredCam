{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98517245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "# Principales acciones entre 2003 y 2008\n",
    "import glob\n",
    "import pandas as pd  # type: ignore\n",
    "\n",
    "files = glob.glob(\"../files/input/*.csv.zip\")\n",
    "\n",
    "quotes = []\n",
    "for file in files:\n",
    "    quotes.append(pd.read_csv(file, compression=\"zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277e8c9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Calculo de las variaciones diarias\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m close_prices = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mq\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclose\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mquotes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m open_prices = np.vstack([q[\u001b[33m\"\u001b[39m\u001b[33mopen\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m quotes])\n\u001b[32m      6\u001b[39m variation = close_prices - open_prices\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\UNAL\\2025-1S\\Fundamentos de analitica\\PRE-27-prediccion-basica-series-de-tiempo-JhofredCam\\.venv\\Lib\\site-packages\\numpy\\_core\\shape_base.py:292\u001b[39m, in \u001b[36mvstack\u001b[39m\u001b[34m(tup, dtype, casting)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    291\u001b[39m     arrs = (arrs,)\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "# Calculo de las variaciones diarias\n",
    "import numpy as np  # type: ignore\n",
    "\n",
    "close_prices = np.vstack([q[\"close\"] for q in quotes])\n",
    "open_prices = np.vstack([q[\"open\"] for q in quotes])\n",
    "variation = close_prices - open_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d43616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aprendizaje de la estructura gráfica\n",
    "from sklearn import covariance\n",
    "\n",
    "alphas = np.logspace(-1.5, 1, num=10)\n",
    "edge_model = covariance.GraphicalLassoCV(alphas=alphas)\n",
    "\n",
    "# Usa la correlación en lugar de la covarianza\n",
    "X = variation.copy().T\n",
    "X /= X.std(axis=0)\n",
    "edge_model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d40aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres de las acciones\n",
    "symbol_dict = {\n",
    "    \"TOT\": \"Total\", \"XOM\": \"Exxon\", \"CVX\": \"Chevron\", \"COP\": \"ConocoPhillips\", \"VLO\": \"Valero Energy\",\n",
    "    \"MSFT\": \"Microsoft\", \"IBM\": \"IBM\", \"TWX\": \"Time Warner\", \"CMCSA\": \"Comcast\", \"CVC\": \"Cablevision\",\n",
    "    \"YHOO\": \"Yahoo\", \"DELL\": \"Dell\", \"HPQ\": \"HP\", \"AMZN\": \"Amazon\", \"TM\": \"Toyota\", \"CAJ\": \"Canon\",\n",
    "    \"SNE\": \"Sony\", \"F\": \"Ford\", \"HMC\": \"Honda\", \"NAV\": \"Navistar\", \"NOC\": \"Northrop Grumman\",\n",
    "    \"BA\": \"Boeing\", \"KO\": \"Coca Cola\", \"MMM\": \"3M\", \"MCD\": \"McDonald's\", \"PEP\": \"Pepsi\", \"K\": \"Kellogg\",\n",
    "    \"UN\": \"Unilever\", \"MAR\": \"Marriott\", \"PG\": \"Procter Gamble\", \"CL\": \"Colgate-Palmolive\",\n",
    "    \"GE\": \"General Electrics\", \"WFC\": \"Wells Fargo\", \"JPM\": \"JPMorgan Chase\", \"AIG\": \"AIG\",\n",
    "    \"AXP\": \"American express\", \"BAC\": \"Bank of America\", \"GS\": \"Goldman Sachs\", \"AAPL\": \"Apple\",\n",
    "    \"SAP\": \"SAP\", \"CSCO\": \"Cisco\", \"TXN\": \"Texas Instruments\", \"XRX\": \"Xerox\", \"WMT\": \"Wal-Mart\",\n",
    "    \"HD\": \"Home Depot\", \"GSK\": \"GlaxoSmithKline\", \"PFE\": \"Pfizer\", \"SNY\": \"Sanofi-Aventis\",\n",
    "    \"NVS\": \"Novartis\", \"KMB\": \"Kimberly-Clark\", \"R\": \"Ryder\", \"GD\": \"General Dynamics\",\n",
    "    \"RTN\": \"Raytheon\", \"CVS\": \"CVS\", \"CAT\": \"Caterpillar\", \"DD\": \"DuPont de Nemours\"\n",
    "}\n",
    "\n",
    "symbols, names = np.array(sorted(symbol_dict.items())).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ca20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "from sklearn import cluster\n",
    "\n",
    "_, labels = cluster.affinity_propagation(edge_model.covariance_, random_state=0)\n",
    "n_labels = labels.max()\n",
    "\n",
    "for i in range(n_labels + 1):\n",
    "    print(f\"Cluster {i + 1}: {', '.join(names[labels == i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "plt.figure(1, facecolor=\"w\", figsize=(10, 8))\n",
    "\n",
    "plt.clf()\n",
    "ax = plt.axes([0.0, 0.0, 1.0, 1.0])\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Muestra la grafica de las correlaciones parciales\n",
    "partial_correlations = edge_model.precision_.copy()\n",
    "d = 1 / np.sqrt(np.diag(partial_correlations))\n",
    "partial_correlations *= d\n",
    "partial_correlations *= d[:, np.newaxis]\n",
    "non_zero = np.abs(np.triu(partial_correlations, k=1)) > 0.02\n",
    "\n",
    "# Grafica los nodos usando las coordenadas del embedding\n",
    "plt.scatter(\n",
    "    embedding[0], embedding[1], s=100 * d**2, c=labels, cmap=plt.cm.nipy_spectral\n",
    ")\n",
    "\n",
    "# Grafica los bordes\n",
    "start_idx, end_idx = np.where(non_zero)\n",
    "segments = [\n",
    "    [embedding[:, start], embedding[:, stop]] for start, stop in zip(start_idx, end_idx)\n",
    "]\n",
    "values = np.abs(partial_correlations[non_zero])\n",
    "lc = LineCollection(\n",
    "    segments, zorder=0, cmap=plt.cm.hot_r, norm=plt.Normalize(0, 0.7 * values.max())\n",
    ")\n",
    "lc.set_array(values)\n",
    "lc.set_linewidths(15 * values)\n",
    "ax.add_collection(lc)\n",
    "\n",
    "# Etiquetas\n",
    "for index, (name, label, (x, y)) in enumerate(zip(names, labels, embedding.T)):\n",
    "    dx = x - embedding[0]\n",
    "    dx[index] = 1\n",
    "    dy = y - embedding[1]\n",
    "    dy[index] = 1\n",
    "    this_dx = dx[np.argmin(np.abs(dy))]\n",
    "    this_dy = dy[np.argmin(np.abs(dx))]\n",
    "    if this_dx > 0:\n",
    "        horizontalalignment = \"left\"\n",
    "        x = x + 0.002\n",
    "    else:\n",
    "        horizontalalignment = \"right\"\n",
    "        x = x - 0.002\n",
    "    if this_dy > 0:\n",
    "        verticalalignment = \"bottom\"\n",
    "        y = y + 0.002\n",
    "    else:\n",
    "        verticalalignment = \"top\"\n",
    "        y = y - 0.002\n",
    "    plt.text(\n",
    "        x,\n",
    "        y,\n",
    "        name,\n",
    "        size=10,\n",
    "        horizontalalignment=horizontalalignment,\n",
    "        verticalalignment=verticalalignment,\n",
    "        bbox=dict(\n",
    "            facecolor=\"w\",\n",
    "            edgecolor=plt.cm.nipy_spectral(label / float(n_labels)),\n",
    "            alpha=0.6,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "plt.xlim(\n",
    "    embedding[0].min() - 0.15 * np.ptp(embedding[0]),\n",
    "    embedding[0].max() + 0.10 * np.ptp(embedding[0]),\n",
    ")\n",
    "plt.ylim(\n",
    "    embedding[1].min() - 0.03 * np.ptp(embedding[1]),\n",
    "    embedding[1].max() + 0.03 * np.ptp(embedding[1]),\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a5aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda la figura\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"../files/output\"):\n",
    "    os.makedirs(\"../files/output\")\n",
    "\n",
    "plt.savefig(\"../files/output/stocks.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
